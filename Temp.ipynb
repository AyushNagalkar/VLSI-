{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676318f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install PyTorch first (CUDA 11.8)\n",
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118 -q\n",
    "\n",
    "# Install PyTorch Geometric and extensions using pre-built wheels\n",
    "!pip install torch-geometric -q\n",
    "!pip install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.7.0+cu118.html -q\n",
    "\n",
    "# Install other utilities\n",
    "!pip install matplotlib numpy scipy pandas psutil -q\n",
    "\n",
    "print(\"All packages installed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94ab990",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "# PyTorch Geometric\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GATConv, GCNConv\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "# Numerical and visualization\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "# System utilities\n",
    "import os\n",
    "import time\n",
    "import gc\n",
    "import psutil\n",
    "from scipy.spatial import KDTree\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "# Check GPU availability\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "print(f\"   PyTorch version: {torch.__version__}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"   GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "\n",
    "print(\"\\nAll libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64c3c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# CONFIGURE YOUR CIRCUITNET PATHS HERE\n",
    "# ============================================\n",
    "\n",
    "CIRCUITNET_BASE = r\"H:\\Labs\\Generative Ai\\Ayush1\\Ayush\\CircuitNet\"\n",
    "\n",
    "# Data paths\n",
    "PLACEMENT_PATH = os.path.join(CIRCUITNET_BASE, \"instance_placement_micron-002\", \"instance_placement_micron\")\n",
    "NODE_ATTR_PATH = os.path.join(CIRCUITNET_BASE, \"graph_features\", \"graph_information\", \"node_attr\")\n",
    "NET_ATTR_PATH = os.path.join(CIRCUITNET_BASE, \"graph_features\", \"graph_information\", \"net_attr\")\n",
    "PIN_ATTR_PATH = os.path.join(CIRCUITNET_BASE, \"graph_features\", \"graph_information\", \"pin_attr\")\n",
    "CONGESTION_PATH = os.path.join(CIRCUITNET_BASE, \"congestion\")\n",
    "\n",
    "# Verify paths exist\n",
    "print(\"Verifying dataset paths...\\n\")\n",
    "\n",
    "paths_to_check = {\n",
    "    \"Base Directory\": CIRCUITNET_BASE,\n",
    "    \"Placement Data\": PLACEMENT_PATH,\n",
    "    \"Node Attributes\": NODE_ATTR_PATH,\n",
    "    \"Net Attributes\": NET_ATTR_PATH,\n",
    "    \"Pin Attributes\": PIN_ATTR_PATH,\n",
    "}\n",
    "\n",
    "all_exist = True\n",
    "for name, path in paths_to_check.items():\n",
    "    exists = os.path.exists(path)\n",
    "    status = \"[OK]\" if exists else \"[MISSING]\"\n",
    "    print(f\"{status} {name}: {path}\")\n",
    "    if not exists:\n",
    "        all_exist = False\n",
    "\n",
    "print()\n",
    "if all_exist:\n",
    "    print(\"All paths verified! Ready to load data.\")\n",
    "else:\n",
    "    print(\"WARNING: Some paths are missing. Please check your CircuitNet installation.\")\n",
    "    print(\"\\nDownload from: https://drive.google.com/drive/folders/1GjW-1LBx1563bg3pHQGvhcEyK2A9sYUB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08b4da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "MAX_SAMPLES = 500  # Increased from 100 for better generalization\n",
    "\n",
    "print(f\"Loading {MAX_SAMPLES} samples from CircuitNet...\\n\")\n",
    "circuitnet_dataset = load_circuitnet_dataset(max_samples=MAX_SAMPLES)\n",
    "\n",
    "if circuitnet_dataset:\n",
    "    # Split into train/test (80/20)\n",
    "    split_idx = int(len(circuitnet_dataset) * 0.8)\n",
    "    cn_train = circuitnet_dataset[:split_idx]\n",
    "    cn_test = circuitnet_dataset[split_idx:]\n",
    "    \n",
    "    print(f\"\\nDataset Statistics:\")\n",
    "    print(f\"   Total samples: {len(circuitnet_dataset)}\")\n",
    "    print(f\"   Training samples: {len(cn_train)}\")\n",
    "    print(f\"   Test samples: {len(cn_test)}\")\n",
    "    print(f\"   Cells per sample: ~{circuitnet_dataset[0].num_cells:,}\")\n",
    "    print(f\"   Edges per sample: ~{circuitnet_dataset[0].edge_index.shape[1]:,}\")\n",
    "    print(f\"\\nDataset ready for training!\")\n",
    "else:\n",
    "    print(\"Failed to load dataset. Check your paths!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1c2def",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VLSIPlacementGNN(nn.Module):\n",
    "    \"\"\"\n",
    "    Graph Attention Network for VLSI cell placement prediction\n",
    "    \n",
    "    Industry-Aware Architecture (v2 - Anti-Collapse):\n",
    "    - Input: 16 features per cell (size, connectivity, macro classification, context)\n",
    "    - 4 GAT layers with multi-head attention + residual connections\n",
    "    - NO Sigmoid bottleneck - uses scaled tanh for full [0,1] range utilization\n",
    "    - Residual connections prevent gradient vanishing in deep GNN\n",
    "    - Output: (x, y) coordinates for each cell\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim=16, hidden_dim=128, output_dim=2, num_layers=4, heads=4):\n",
    "        super(VLSIPlacementGNN, self).__init__()\n",
    "        \n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        # Input projection\n",
    "        self.input_proj = nn.Linear(input_dim, hidden_dim)\n",
    "        self.input_norm = nn.LayerNorm(hidden_dim)\n",
    "        \n",
    "        # GAT layers with attention + layer norms for residual connections\n",
    "        self.gat_layers = nn.ModuleList()\n",
    "        self.layer_norms = nn.ModuleList()\n",
    "        for i in range(num_layers):\n",
    "            in_channels = hidden_dim\n",
    "            out_channels = hidden_dim\n",
    "            self.gat_layers.append(\n",
    "                GATConv(in_channels, out_channels // heads, heads=heads, dropout=0.1, concat=True)\n",
    "            )\n",
    "            self.layer_norms.append(nn.LayerNorm(hidden_dim))\n",
    "        \n",
    "        # Output projection - no Sigmoid! Use clamped output instead\n",
    "        # Sigmoid causes center collapse by squashing gradients at extremes\n",
    "        self.output_proj = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(hidden_dim // 2, output_dim)\n",
    "        )\n",
    "    \n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        \n",
    "        # Input projection\n",
    "        x = self.input_proj(x)\n",
    "        x = self.input_norm(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        # GAT layers with RESIDUAL connections\n",
    "        for i, (gat_layer, layer_norm) in enumerate(zip(self.gat_layers, self.layer_norms)):\n",
    "            residual = x\n",
    "            x = gat_layer(x, edge_index)\n",
    "            x = layer_norm(x)\n",
    "            if i < len(self.gat_layers) - 1:\n",
    "                x = F.relu(x)\n",
    "                x = F.dropout(x, p=0.1, training=self.training)\n",
    "            # Residual connection - prevents information loss in deep GNN\n",
    "            x = x + residual\n",
    "        \n",
    "        # Output projection\n",
    "        out = self.output_proj(x)\n",
    "        \n",
    "        # Clamp to [0, 1] instead of Sigmoid\n",
    "        # This preserves gradients at boundaries (Sigmoid kills them)\n",
    "        out = out.clamp(0.0, 1.0)\n",
    "        \n",
    "        return out\n",
    "\n",
    "# Create model with 16 input features (industry-relevant)\n",
    "model = VLSIPlacementGNN(\n",
    "    input_dim=16,      # 16 industry-relevant features\n",
    "    hidden_dim=128,\n",
    "    output_dim=2,\n",
    "    num_layers=4,\n",
    "    heads=4\n",
    ").to(device)\n",
    "\n",
    "# Count parameters\n",
    "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(\"Model Architecture (v2 - Anti-Collapse):\\n\")\n",
    "print(model)\n",
    "print(f\"\\nModel Statistics:\")\n",
    "print(f\"   Total parameters: {num_params:,}\")\n",
    "print(f\"   Input features: 16 dimensions (industry-relevant)\")\n",
    "print(f\"   Key improvements over v1:\")\n",
    "print(f\"     - Residual connections (prevents gradient vanishing)\")\n",
    "print(f\"     - LayerNorm (stabilizes training)\")\n",
    "print(f\"     - No Sigmoid (prevents center collapse)\")\n",
    "print(f\"     - Clamp [0,1] output (preserves gradients at boundaries)\")\n",
    "print(f\"   Device: {device}\")\n",
    "print(\"\\nModel created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede207b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop with resume capability\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "start_epoch = 0\n",
    "\n",
    "# Check if model exists and load it\n",
    "model_save_path = r\"H:\\Labs\\Generative Ai\\Ayush\\vlsi_placement_model.pth\"\n",
    "\n",
    "if os.path.exists(model_save_path):\n",
    "    print(\"=\" * 80)\n",
    "    print(\"LOADING EXISTING MODEL\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    checkpoint = torch.load(model_save_path)\n",
    "    \n",
    "    # Check if saved model has same architecture (input_dim may differ)\n",
    "    saved_config = checkpoint.get('model_config', {})\n",
    "    saved_input_dim = saved_config.get('input_dim', 10)\n",
    "    current_input_dim = model.input_dim\n",
    "    \n",
    "    if saved_input_dim != current_input_dim:\n",
    "        print(f\"   WARNING: Saved model has input_dim={saved_input_dim}, current model has input_dim={current_input_dim}\")\n",
    "        print(f\"   Architecture changed (new industry-relevant features). Training from scratch.\")\n",
    "        print(\"=\" * 80)\n",
    "        print()\n",
    "    else:\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        start_epoch = checkpoint['epoch']\n",
    "        train_losses = checkpoint.get('train_losses', [])\n",
    "        test_losses = checkpoint.get('test_losses', [])\n",
    "        \n",
    "        print(f\"Model loaded from: {model_save_path}\")\n",
    "        print(f\"   Previous epochs completed: {start_epoch}\")\n",
    "        print(f\"   Previous train loss: {train_losses[-1]:.6f}\" if train_losses else \"   No previous train loss\")\n",
    "        print(f\"   Previous test loss: {test_losses[-1]:.6f}\" if test_losses else \"   No previous test loss\")\n",
    "        print(f\"   Resuming training from epoch {start_epoch + 1}\")\n",
    "        print(\"=\" * 80)\n",
    "        print()\n",
    "else:\n",
    "    print(\"=\" * 80)\n",
    "    print(\"STARTING TRAINING FROM SCRATCH\")\n",
    "    print(\"=\" * 80)\n",
    "    print()\n",
    "\n",
    "print(\"Starting Training...\\n\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(start_epoch, start_epoch + NUM_EPOCHS):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    batch_count = 0\n",
    "    \n",
    "    # Training\n",
    "    for data in cn_train:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        pred = model(data)\n",
    "        loss = criterion(pred, data.y)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        batch_count += 1\n",
    "    \n",
    "    avg_train_loss = epoch_loss / batch_count\n",
    "    train_losses.append(avg_train_loss)\n",
    "    \n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    test_count = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data in cn_test:\n",
    "            data = data.to(device)\n",
    "            pred = model(data)\n",
    "            loss = criterion(pred, data.y)\n",
    "            test_loss += loss.item()\n",
    "            test_count += 1\n",
    "    \n",
    "    avg_test_loss = test_loss / test_count\n",
    "    test_losses.append(avg_test_loss)\n",
    "    \n",
    "    # Print progress\n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"Epoch {epoch+1:2d}/{start_epoch + NUM_EPOCHS} | \"\n",
    "          f\"Train Loss: {avg_train_loss:.6f} | \"\n",
    "          f\"Test Loss: {avg_test_loss:.6f} | \"\n",
    "          f\"Time: {elapsed:.1f}s\")\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nTraining complete! Total time: {elapsed/60:.1f} minutes\")\n",
    "print(f\"   Final train loss: {train_losses[-1]:.6f}\")\n",
    "print(f\"   Final test loss: {test_losses[-1]:.6f}\")\n",
    "print(f\"   Total epochs completed: {start_epoch + NUM_EPOCHS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0e8f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "model_save_path = r\"H:\\Labs\\Generative Ai\\Ayush1\\Ayush\\vlsi_placement_model.pth\"\n",
    "\n",
    "# Calculate total epochs (start_epoch + NUM_EPOCHS)\n",
    "total_epochs = start_epoch + NUM_EPOCHS\n",
    "\n",
    "torch.save({\n",
    "    'epoch': total_epochs,\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'train_losses': train_losses,\n",
    "    'test_losses': test_losses,\n",
    "    'model_config': {\n",
    "        'input_dim': 16,\n",
    "        'hidden_dim': 128,\n",
    "        'output_dim': 2,\n",
    "        'num_layers': 4,\n",
    "        'heads': 4\n",
    "    }\n",
    "}, model_save_path)\n",
    "\n",
    "print(f\"Model saved to: {model_save_path}\")\n",
    "print(f\"   Total epochs completed: {total_epochs}\")\n",
    "print(f\"   File size: {os.path.getsize(model_save_path) / 1e6:.2f} MB\")\n",
    "print(f\"\\nTo load later:\")\n",
    "print(f\"   checkpoint = torch.load('{model_save_path}')\")\n",
    "print(f\"   model.load_state_dict(checkpoint['model_state_dict'])\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f065c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_industry_layout(data, predictions, chip_width_microns=1000, chip_height_microns=1000, dpi=150):\n",
    "    \"\"\"\n",
    "    Industry-grade layout visualization with micron precision\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 8), dpi=dpi)\n",
    "    \n",
    "    # Convert normalized coordinates to microns\n",
    "    predicted_microns = predictions * np.array([chip_width_microns, chip_height_microns])\n",
    "    actual_microns = data.y.cpu().numpy() * np.array([chip_width_microns, chip_height_microns])\n",
    "    \n",
    "    # Plot 1: Predicted Layout\n",
    "    ax1 = axes[0]\n",
    "    ax1.set_xlim(0, chip_width_microns)\n",
    "    ax1.set_ylim(0, chip_height_microns)\n",
    "    ax1.set_aspect('equal')\n",
    "    ax1.set_facecolor('#1a1a1a')\n",
    "    \n",
    "    # Draw cells with different colors based on size\n",
    "    for i, (x, y) in enumerate(predicted_microns):\n",
    "        # Estimate cell size from node features (simplified)\n",
    "        cell_width = max(5, min(50, data.x[i, 3].item() * 20)) if data.x.shape[1] > 3 else 10\n",
    "        cell_height = cell_width * 0.8\n",
    "        \n",
    "        rect = Rectangle((x - cell_width/2, y - cell_height/2), \n",
    "                        cell_width, cell_height,\n",
    "                        facecolor='cyan', edgecolor='white', \n",
    "                        alpha=0.7, linewidth=0.5)\n",
    "        ax1.add_patch(rect)\n",
    "    \n",
    "    # Draw connections (sample)\n",
    "    edge_index = data.edge_index.cpu().numpy()\n",
    "    for i in range(0, min(500, edge_index.shape[1]), 5):  # Sample edges\n",
    "        src, dst = edge_index[:, i]\n",
    "        ax1.plot([predicted_microns[src, 0], predicted_microns[dst, 0]],\n",
    "                [predicted_microns[src, 1], predicted_microns[dst, 1]],\n",
    "                'yellow', alpha=0.2, linewidth=0.3)\n",
    "    \n",
    "    ax1.set_title('Predicted Layout (Micron Precision)', fontsize=14, color='white', pad=20)\n",
    "    ax1.set_xlabel('X Position (µm)', fontsize=12, color='white')\n",
    "    ax1.set_ylabel('Y Position (µm)', fontsize=12, color='white')\n",
    "    ax1.tick_params(colors='white')\n",
    "    ax1.grid(True, alpha=0.2, color='gray')\n",
    "    \n",
    "    # Plot 2: Actual Layout\n",
    "    ax2 = axes[1]\n",
    "    ax2.set_xlim(0, chip_width_microns)\n",
    "    ax2.set_ylim(0, chip_height_microns)\n",
    "    ax2.set_aspect('equal')\n",
    "    ax2.set_facecolor('#1a1a1a')\n",
    "    \n",
    "    for i, (x, y) in enumerate(actual_microns):\n",
    "        cell_width = max(5, min(50, data.x[i, 3].item() * 20)) if data.x.shape[1] > 3 else 10\n",
    "        cell_height = cell_width * 0.8\n",
    "        \n",
    "        rect = Rectangle((x - cell_width/2, y - cell_height/2), \n",
    "                        cell_width, cell_height,\n",
    "                        facecolor='lime', edgecolor='white', \n",
    "                        alpha=0.7, linewidth=0.5)\n",
    "        ax2.add_patch(rect)\n",
    "    \n",
    "    # Draw connections\n",
    "    for i in range(0, min(500, edge_index.shape[1]), 5):\n",
    "        src, dst = edge_index[:, i]\n",
    "        ax2.plot([actual_microns[src, 0], actual_microns[dst, 0]],\n",
    "                [actual_microns[src, 1], actual_microns[dst, 1]],\n",
    "                'yellow', alpha=0.2, linewidth=0.3)\n",
    "    \n",
    "    ax2.set_title('Actual Layout (Ground Truth)', fontsize=14, color='white', pad=20)\n",
    "    ax2.set_xlabel('X Position (µm)', fontsize=12, color='white')\n",
    "    ax2.set_ylabel('Y Position (µm)', fontsize=12, color='white')\n",
    "    ax2.tick_params(colors='white')\n",
    "    ax2.grid(True, alpha=0.2, color='gray')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('industry_layout.png', dpi=dpi, facecolor='#1a1a1a')\n",
    "    plt.show()\n",
    "    \n",
    "    # Calculate metrics\n",
    "    mse = np.mean((predicted_microns - actual_microns) ** 2)\n",
    "    mae = np.mean(np.abs(predicted_microns - actual_microns))\n",
    "    \n",
    "    print(f\"\\nLayout Accuracy Metrics:\")\n",
    "    print(f\"   Mean Squared Error: {mse:.2f} µm²\")\n",
    "    print(f\"   Mean Absolute Error: {mae:.2f} µm\")\n",
    "    print(f\"   Average X Error: {np.mean(np.abs(predicted_microns[:, 0] - actual_microns[:, 0])):.2f} µm\")\n",
    "    print(f\"   Average Y Error: {np.mean(np.abs(predicted_microns[:, 1] - actual_microns[:, 1])):.2f} µm\")\n",
    "\n",
    "# Visualize with test data\n",
    "print(\"Creating industry-grade layout visualization...\")\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_data = cn_test[10].to(device)\n",
    "    test_pred = model(test_data).cpu().numpy()\n",
    "\n",
    "visualize_industry_layout(test_data, test_pred)\n",
    "print(\"Industry-grade visualization complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ac9513",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb7645d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1fbcc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef786a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
